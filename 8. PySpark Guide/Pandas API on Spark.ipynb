{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas API on Spark\n",
    "\n",
    "Shows the key difference between pandas and pandasAPI on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Creation\n",
    "\n",
    "Creating Series, DataFrames and other data structures using the pandas API on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    3.0\n",
       "2    5.0\n",
       "3    NaN\n",
       "4    6.0\n",
       "5    8.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Series\n",
    "s = ps.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame\n",
    "psdf = ps.DataFrame(\n",
    "  {'a': [1, 2, 3, 4, 5, 6],\n",
    "    'b': [100, 200, 300, 400, 500, 600],\n",
    "    'c': [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\"]},\n",
    "  index=[10, 20, 30, 40, 50, 60]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>600</td>\n",
       "      <td>six</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    a    b      c\n",
       "10  1  100    one\n",
       "20  2  200    two\n",
       "30  3  300  three\n",
       "40  4  400   four\n",
       "50  5  500   five\n",
       "60  6  600    six"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.870151</td>\n",
       "      <td>-0.543835</td>\n",
       "      <td>-1.417537</td>\n",
       "      <td>0.071349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.745022</td>\n",
       "      <td>-0.659855</td>\n",
       "      <td>-0.266685</td>\n",
       "      <td>-0.998854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.398669</td>\n",
       "      <td>-0.902246</td>\n",
       "      <td>2.055565</td>\n",
       "      <td>0.279596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.331432</td>\n",
       "      <td>0.087261</td>\n",
       "      <td>-0.165452</td>\n",
       "      <td>1.178686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>-1.209078</td>\n",
       "      <td>-0.504687</td>\n",
       "      <td>-1.735076</td>\n",
       "      <td>0.039445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>-1.728753</td>\n",
       "      <td>-1.948222</td>\n",
       "      <td>-0.822342</td>\n",
       "      <td>-0.032405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D\n",
       "2013-01-01  1.870151 -0.543835 -1.417537  0.071349\n",
       "2013-01-02 -0.745022 -0.659855 -0.266685 -0.998854\n",
       "2013-01-03  0.398669 -0.902246  2.055565  0.279596\n",
       "2013-01-04 -0.331432  0.087261 -0.165452  1.178686\n",
       "2013-01-05 -1.209078 -0.504687 -1.735076  0.039445\n",
       "2013-01-06 -1.728753 -1.948222 -0.822342 -0.032405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting pandas df to Spark\n",
    "## Create the dataframe\n",
    "dates = pd.date_range('20130101', periods=6)\n",
    "pdf = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list('ABCD'))\n",
    "\n",
    "## Convert to Spark\n",
    "psdf = ps.from_pandas(pdf)\n",
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('PandasAPI on Spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+--------------------+\n",
      "|                  A|                  B|                   C|                   D|\n",
      "+-------------------+-------------------+--------------------+--------------------+\n",
      "| 1.8701514588824242| -0.543835011119871|   -1.41753667282922| 0.07134888329338522|\n",
      "|-0.7450220752252489| -0.659854835580294| -0.2666846622186714| -0.9988544962042697|\n",
      "| 0.3986688111562146|-0.9022459232441857|   2.055565239195255|  0.2795957852989773|\n",
      "| -0.331431597751275|0.08726078212486754|-0.16545196196832423|  1.1786862161532354|\n",
      "|-1.2090782063201833|-0.5046865940547667| -1.7350759780205685|0.039445036289597696|\n",
      "|-1.7287528898005402|-1.9482221773587187| -0.8223418784833127|-0.03240532656591444|\n",
      "+-------------------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark DataFrame (not pandasAPI DataFrame on Spark)\n",
    "sdf = spark.createDataFrame(pdf)\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.870151</td>\n",
       "      <td>-0.543835</td>\n",
       "      <td>-1.417537</td>\n",
       "      <td>0.071349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.745022</td>\n",
       "      <td>-0.659855</td>\n",
       "      <td>-0.266685</td>\n",
       "      <td>-0.998854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.398669</td>\n",
       "      <td>-0.902246</td>\n",
       "      <td>2.055565</td>\n",
       "      <td>0.279596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.331432</td>\n",
       "      <td>0.087261</td>\n",
       "      <td>-0.165452</td>\n",
       "      <td>1.178686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.209078</td>\n",
       "      <td>-0.504687</td>\n",
       "      <td>-1.735076</td>\n",
       "      <td>0.039445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.728753</td>\n",
       "      <td>-1.948222</td>\n",
       "      <td>-0.822342</td>\n",
       "      <td>-0.032405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D\n",
       "0  1.870151 -0.543835 -1.417537  0.071349\n",
       "1 -0.745022 -0.659855 -0.266685 -0.998854\n",
       "2  0.398669 -0.902246  2.055565  0.279596\n",
       "3 -0.331432  0.087261 -0.165452  1.178686\n",
       "4 -1.209078 -0.504687 -1.735076  0.039445\n",
       "5 -1.728753 -1.948222 -0.822342 -0.032405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Spark DF to PandasAPI on Spark\n",
    "psdf = sdf.pandas_api()\n",
    "psdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All common functions are also available\n",
    "psdf.dtypes\n",
    "psdf.head()\n",
    "psdf.index\n",
    "psdf.columns\n",
    "psdf.to_numpy()\n",
    "psdf.describe()\n",
    "psdf.T\n",
    "psdf.sort_index()\n",
    "psdf.sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data\n",
    "\n",
    "Pandas API on Spark uses `np.nan` to represent missing data. Default not included during computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.870151</td>\n",
       "      <td>-0.543835</td>\n",
       "      <td>-1.417537</td>\n",
       "      <td>0.071349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.745022</td>\n",
       "      <td>-0.659855</td>\n",
       "      <td>-0.266685</td>\n",
       "      <td>-0.998854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.398669</td>\n",
       "      <td>-0.902246</td>\n",
       "      <td>2.055565</td>\n",
       "      <td>0.279596</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.331432</td>\n",
       "      <td>0.087261</td>\n",
       "      <td>-0.165452</td>\n",
       "      <td>1.178686</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D    E\n",
       "2013-01-01  1.870151 -0.543835 -1.417537  0.071349  1.0\n",
       "2013-01-02 -0.745022 -0.659855 -0.266685 -0.998854  1.0\n",
       "2013-01-03  0.398669 -0.902246  2.055565  0.279596  NaN\n",
       "2013-01-04 -0.331432  0.087261 -0.165452  1.178686  NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconfigure dataframe to include NaNs\n",
    "pdf1 = pdf.reindex(index=dates[0:4], columns=list(pdf.columns) + ['E'])\n",
    "pdf1.loc[dates[0]:dates[1], 'E'] = 1\n",
    "psdf1 = ps.from_pandas(pdf1)\n",
    "psdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.870151</td>\n",
       "      <td>-0.543835</td>\n",
       "      <td>-1.417537</td>\n",
       "      <td>0.071349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.745022</td>\n",
       "      <td>-0.659855</td>\n",
       "      <td>-0.266685</td>\n",
       "      <td>-0.998854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D    E\n",
       "2013-01-01  1.870151 -0.543835 -1.417537  0.071349  1.0\n",
       "2013-01-02 -0.745022 -0.659855 -0.266685 -0.998854  1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping na\n",
    "psdf1.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>1.870151</td>\n",
       "      <td>-0.543835</td>\n",
       "      <td>-1.417537</td>\n",
       "      <td>0.071349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>-0.745022</td>\n",
       "      <td>-0.659855</td>\n",
       "      <td>-0.266685</td>\n",
       "      <td>-0.998854</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.398669</td>\n",
       "      <td>-0.902246</td>\n",
       "      <td>2.055565</td>\n",
       "      <td>0.279596</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.331432</td>\n",
       "      <td>0.087261</td>\n",
       "      <td>-0.165452</td>\n",
       "      <td>1.178686</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   A         B         C         D    E\n",
       "2013-01-01  1.870151 -0.543835 -1.417537  0.071349  1.0\n",
       "2013-01-02 -0.745022 -0.659855 -0.266685 -0.998854  1.0\n",
       "2013-01-03  0.398669 -0.902246  2.055565  0.279596  5.0\n",
       "2013-01-04 -0.331432  0.087261 -0.165452  1.178686  5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psdf1.fillna(value=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "Different \"group by\" operations:\n",
    "\n",
    "* Splitting data into groups based on some criteria\n",
    "* Applying a function to each group independently\n",
    "* Combinding the results into a data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf = ps.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B': ['one', 'one', 'two', 'three',\n",
    "                          'two', 'two', 'one', 'three'],\n",
    "                    'C': np.random.randn(8),\n",
    "                    'D': np.random.randn(8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>foo</th>\n",
       "      <td>0.545007</td>\n",
       "      <td>-0.999114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bar</th>\n",
       "      <td>-2.007125</td>\n",
       "      <td>1.960935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C         D\n",
       "A                      \n",
       "foo  0.545007 -0.999114\n",
       "bar -2.007125  1.960935"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by and aggregate\n",
    "psdf.groupby('A').sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting/ Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psdf.to_csv('foo.csv')\n",
    "psdf.read_csv('foo.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Configurations\n",
    "\n",
    "Various combinations in PySpark can be applied internally in pandas API on Spark using the `.conf.set()` command\n",
    "\n",
    "A full list of configurations can be found [here](https://spark.apache.org/docs/latest/configuration.html#spark-properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current configuration: false\n"
     ]
    }
   ],
   "source": [
    "# Getting the current configuration\n",
    "prev = spark.conf.get('spark.sql.execution.arrow.pyspark.enabled')\n",
    "print(f\"Current configuration: {prev}\")\n",
    "\n",
    "# Changing the option\n",
    "ps.set_option('compute.default_index_type', 'distributed')\n",
    "\n",
    "import warnings\n",
    "# Changing wanring options\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 ms ± 23.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Setting general Spark configurations\n",
    "## Enabling pyspark arrow optimization\n",
    "spark.conf.set('spark.sql.execution.arrow.pyspark.enabled', True)\n",
    "%timeit ps.range(3000).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899 ms ± 46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## Disabling and comparing speed\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", False)\n",
    "%timeit ps.range(300000).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseting options to default\n",
    "ps.reset_option(\"compute.default_index_type\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", prev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc1f4863a5dfb7e90f6f0646481ce38df4cdefdf4614ba08727c157218b20914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
