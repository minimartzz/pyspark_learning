{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName('MLIntro') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train = spark.read.csv('housing.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+--------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_prox_num|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+--------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|           3.0|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|           3.0|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|           3.0|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|           3.0|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|           3.0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "`VectorAssembler` is used by PySpark to combine a list of columns into a single vector column. Usually used to combine raw features and features from transformations in order to train ML models \n",
    "\n",
    "`StringIndexer` is used to convert string data types into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+--------------+---------------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_prox_num|Independent Variables|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+--------------+---------------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|           3.0| [-122.23,37.88,41...|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|           3.0| [-122.22,37.86,21...|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|           3.0| [-122.24,37.85,52...|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|           3.0| [-122.25,37.85,52...|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|           3.0| [-122.25,37.85,52...|\n",
      "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|           3.0| [-122.25,37.85,52...|\n",
      "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|           3.0| [-122.25,37.84,52...|\n",
      "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|           3.0| [-122.25,37.84,52...|\n",
      "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|           3.0| [-122.26,37.84,42...|\n",
      "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|           3.0| [-122.25,37.84,52...|\n",
      "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|           3.0| [-122.26,37.85,52...|\n",
      "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|           3.0| [-122.26,37.85,52...|\n",
      "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|           3.0| [-122.26,37.85,52...|\n",
      "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|           3.0| [-122.26,37.84,52...|\n",
      "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|           3.0| [-122.26,37.85,52...|\n",
      "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|           3.0| [-122.26,37.85,50...|\n",
      "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|           3.0| [-122.27,37.85,52...|\n",
      "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|           3.0| [-122.27,37.85,52...|\n",
      "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|           3.0| [-122.26,37.84,50...|\n",
      "|  -122.27|   37.84|              52.0|     1503.0|         298.0|     690.0|     275.0|       2.6033|          162900.0|           3.0| [-122.27,37.84,52...|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+--------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "# Change the string column to a numeric one\n",
    "string_indexer = StringIndexer(\n",
    "  inputCol='ocean_proximity',\n",
    "  outputCol='ocean_prox_num'\n",
    ")\n",
    "train = string_indexer.fit(train).transform(train)\n",
    "train = train.drop('ocean_proximity')\n",
    "\n",
    "# Combining columns into a single column\n",
    "feature_assembler = VectorAssembler(\n",
    "  inputCols=[\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'housing_median_age',\n",
    "    'total_rooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "    'ocean_prox_num'\n",
    "  ],\n",
    "  outputCol=\"Independent Variables\"\n",
    ")\n",
    "train = feature_assembler.transform(train)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+\n",
      "|Independent Variables|median_house_value|\n",
      "+---------------------+------------------+\n",
      "| [-122.23,37.88,41...|          452600.0|\n",
      "| [-122.22,37.86,21...|          358500.0|\n",
      "| [-122.24,37.85,52...|          352100.0|\n",
      "| [-122.25,37.85,52...|          341300.0|\n",
      "| [-122.25,37.85,52...|          342200.0|\n",
      "+---------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = train.select(['Independent Variables', 'median_house_value'])\n",
    "training_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "train_data, test_data = training_data.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Fit model to Linear Regression\n",
    "regressor = LinearRegression(\n",
    "  featuresCol='Independent Variables',\n",
    "  labelCol='median_house_value'\n",
    ")\n",
    "regression = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-42106.9038, -42139.5922, 1150.0765, -2.1397, -44.1553, 153.6768, 38813.7272, -970.7164])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details of ML results\n",
    "regression.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+------------------+\n",
      "|Independent Variables|median_house_value|        prediction|\n",
      "+---------------------+------------------+------------------+\n",
      "| [-124.3,41.84,17....|          103600.0| 98878.21950594336|\n",
      "| [-124.26,40.58,52...|          111400.0| 166869.0367788598|\n",
      "| [-124.25,40.28,32...|           76100.0|134565.36655658018|\n",
      "| [-124.23,41.75,11...|           73200.0| 69576.07339649973|\n",
      "| [-124.19,41.78,15...|           74600.0| 51038.55300127342|\n",
      "+---------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "pred_results = regression.evaluate(test_data)\n",
    "pred_results.predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Absolute Error is 51700.73401185502\n",
      "The Mean Squared Error is 4984424611.6106825\n"
     ]
    }
   ],
   "source": [
    "# Display metrics - across test set\n",
    "print(f\"The Mean Absolute Error is {pred_results.meanAbsoluteError}\")\n",
    "print(f\"The Mean Squared Error is {pred_results.meanSquaredError}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
