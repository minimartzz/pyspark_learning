{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Tuning\n",
    "\n",
    "For some workloads, it is possible to improve performance by either caching data in memory of by turning on some experimental options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching Data in Memory\n",
    "\n",
    "Spark SQL can cache tables using an in-memory columnar format. It will scan only the required columns and will automatically tune compression to minimize memory usage and GC pressure.\n",
    "\n",
    "For caching:\n",
    "\n",
    "* `spark.catalog.cacheTable(\"<tableName>\")\n",
    "* `dataFrame.cache()`\n",
    "\n",
    "For uncaching:\n",
    "\n",
    "* `spark.catalog.uncacheTable(\"<tableName>\")\n",
    "* `dataFrame.unpersist()`\n",
    "\n",
    "Configuration can be done using `setConf` method on SparkSession or running `SET key=value` commands using SQL\n",
    "\n",
    "<u>Configuration Options</u>\n",
    "\n",
    "Note: Everything begins with a `spark.sql` then the config\n",
    "\n",
    "* `inMemoryColumnarStorage.compressed` -- True -- automatically select a compression codec for each column\n",
    "* `inMemoryColumnarStorage.batchSize` -- 10000 -- controls the batch for columnar caching, Larger batch sizes improve memory utilization but risk OOMs when caching data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Configuration Options\n",
    "\n",
    "Find the other configuration options [ here ](https://spark.apache.org/docs/latest/sql-performance-tuning.html#other-configuration-options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Stragety Hints for SQL Queries\n",
    "\n",
    "Instruct Spark to use a hinted strategy when joining separated relations. It will tend to prioritize the type of join strategy selected even if the size of the table suggested by the statistics is above the configuration selected.\n",
    "\n",
    "__Join Methods__\n",
    "\n",
    "* `DataFrame.join(<df>, <on_col>)` -- join 2 dataframes together\n",
    "* `<df>.hint(<join_strategy>)` -- specify the type of join strategy to apply to that side of the the join\n",
    "\n",
    "__Join Strategies__\n",
    "\n",
    "* `BROADCAST`\n",
    "* `MERGE`\n",
    "* `SHUFFLE_HASH`\n",
    "* `SHUFFLE_REPLICATE_NL`\n",
    "\n",
    "Order of prioritization when both sides of the join are specified: Broadcast > Merge > Shuffle Hash > Shuffle Replicate NL\n",
    "\n",
    "No guarantee that Spark will choose the join strategy specified, since the strategy might not support all join types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Join Strategies\").getOrCreate()\n",
    "\n",
    "spark.table(\"src\").join(spark.table(\"records\").hint(\"broadcast\"), \"key\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Query Execution\n",
    "\n",
    "Adaptive Query Execution (AQE) is an optimization technique that makes use of runtime statistics to choose the most effecient query execution plan, which is enabled by default\n",
    "\n",
    "Three major features in AQE: \n",
    "\n",
    "1. Coalescing post-shuffle paritions\n",
    "2. Converting sort-merge join to broadcast join \n",
    "3. Skew join optimization\n",
    "\n",
    "* `spark.sql.adaptive.enabled` -- True/False -- To turn the feature on and off"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
